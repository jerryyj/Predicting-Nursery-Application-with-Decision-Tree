{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements and reading in Nursery dataset into pandas DataFrame\n",
    "- All features in the dataset are categorical\n",
    "- No null values within the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12960 entries, 0 to 12959\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   parents   12960 non-null  object\n",
      " 1   has_nurs  12960 non-null  object\n",
      " 2   form      12960 non-null  object\n",
      " 3   children  12960 non-null  object\n",
      " 4   housing   12960 non-null  object\n",
      " 5   finance   12960 non-null  object\n",
      " 6   social    12960 non-null  object\n",
      " 7   health    12960 non-null  object\n",
      " 8   label     12960 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 911.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12955</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12956</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12957</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>problematic</td>\n",
       "      <td>recommended</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>problematic</td>\n",
       "      <td>priority</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12959</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>problematic</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12960 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          parents   has_nurs      form children     housing     finance  \\\n",
       "0           usual     proper  complete        1  convenient  convenient   \n",
       "1           usual     proper  complete        1  convenient  convenient   \n",
       "2           usual     proper  complete        1  convenient  convenient   \n",
       "3           usual     proper  complete        1  convenient  convenient   \n",
       "4           usual     proper  complete        1  convenient  convenient   \n",
       "...           ...        ...       ...      ...         ...         ...   \n",
       "12955  great_pret  very_crit    foster     more    critical      inconv   \n",
       "12956  great_pret  very_crit    foster     more    critical      inconv   \n",
       "12957  great_pret  very_crit    foster     more    critical      inconv   \n",
       "12958  great_pret  very_crit    foster     more    critical      inconv   \n",
       "12959  great_pret  very_crit    foster     more    critical      inconv   \n",
       "\n",
       "              social       health       label  \n",
       "0            nonprob  recommended   recommend  \n",
       "1            nonprob     priority    priority  \n",
       "2            nonprob    not_recom   not_recom  \n",
       "3      slightly_prob  recommended   recommend  \n",
       "4      slightly_prob     priority    priority  \n",
       "...              ...          ...         ...  \n",
       "12955  slightly_prob     priority  spec_prior  \n",
       "12956  slightly_prob    not_recom   not_recom  \n",
       "12957    problematic  recommended  spec_prior  \n",
       "12958    problematic     priority  spec_prior  \n",
       "12959    problematic    not_recom   not_recom  \n",
       "\n",
       "[12960 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "# Load and read nursery data set into pandas dataframe \n",
    "nurseryDF = pd.read_csv(\"nursery.data\", names=[\"parents\", \"has_nurs\", \"form\", \"children\", \n",
    "                                                \"housing\", \"finance\", \"social\", \"health\",\n",
    "                                                \"label\"])\n",
    "\n",
    "# Print information about dataframe\n",
    "nurseryDF.info()\n",
    "display(nurseryDF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into training, testing and post-pruning sets\n",
    "- Training (60%)\n",
    "- Testing (20%)\n",
    "- Post-pruning (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the data into training, testing and post-pruning sets\n",
    "def train_test_prune_split(df, train_size, test_size):\n",
    "    train_size = round(train_size * len(df))\n",
    "    test_size = round(test_size * len(df))\n",
    "    post_prune_size = len(df) - train_size - test_size\n",
    "    \n",
    "    # Using random sampling to split the data\n",
    "    np.random.seed(10)\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "\n",
    "    train_indices = shuffled_indices[:train_size]\n",
    "    test_indices = shuffled_indices[train_size:train_size + test_size]\n",
    "    post_prune_indices = shuffled_indices[train_size + test_size:]\n",
    "\n",
    "    train_df = df.iloc[train_indices]\n",
    "    test_df = df.iloc[test_indices]\n",
    "    prune_df = df.iloc[post_prune_indices]\n",
    "\n",
    "    return train_df, test_df, prune_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function to split the dataset\n",
    "train_df, test_df, prune_df = train_test_prune_split(nurseryDF, 0.6, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for building the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the data is pure\n",
    "def check_purity(data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    # If no. of unique class is only 1 (out of possuble 5), the data is pure\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Function to classify the data (return the class that has the highest no. of occurence within the dataset)\n",
    "def classify_data(data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification\n",
    "\n",
    "# Function to get all the potential splits while building the decision tree\n",
    "def get_potential_splits(data):\n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "\n",
    "    # Get unique values for each feature\n",
    "    for column_index in range(n_columns - 1): # excludes the last column which is the label\n",
    "        potential_splits[column_index] = []\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "                \n",
    "        potential_splits[column_index] = unique_values\n",
    "    \n",
    "    return potential_splits\n",
    "\n",
    "# Function to split the data into left and right datasets given a split column and value\n",
    "def split_data(data, split_column, split_value):\n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    # Check if column value is equal to split value, store in left dataset if true else store in right dataset\n",
    "    data_left = data[split_column_values == split_value]\n",
    "    data_right = data[split_column_values !=  split_value]\n",
    "    \n",
    "    return data_left, data_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting criteria by Entropy(Information Gain): Helper functions\n",
    "- Lowest entropy for a split will result in the highest information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate entropy\n",
    "def calculate_entropy(data):\n",
    "    \n",
    "    # Get the label values\n",
    "    label_column = data[:, -1]\n",
    "\n",
    "    # Count the number of each unique value\n",
    "    _, unique_counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    # Calculate the probability of each column values\n",
    "    probabilities = unique_counts / unique_counts.sum()\n",
    "\n",
    "    # Compute and return entropy\n",
    "    return sum(probabilities * -np.log2(probabilities))\n",
    "\n",
    "# Function to calculate overall entropy from split\n",
    "def calculate_overall_entropy(data_left, data_right):\n",
    "\n",
    "    n = len(data_left) + len(data_right)\n",
    "    p_data_left = len(data_left) / n\n",
    "    p_data_right = len(data_right) / n\n",
    "\n",
    "    overall_entropy =  (p_data_left * calculate_entropy(data_left) + p_data_right * calculate_entropy(data_right))\n",
    "    \n",
    "    return overall_entropy\n",
    "\n",
    "# Function to determine the best feature and value to be the splitting node through information gain\n",
    "def determine_best_split_IG(data, potential_splits):\n",
    "    \n",
    "    # Instantiate a variable to store the value of the lowest entropy while looping through the potential splits\n",
    "    lowest_entropy = 99999\n",
    "\n",
    "    # Loop through the potential splits (both by column and value)\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            # Call helper functions to split the data and then calculate overall entropy\n",
    "            data_left, data_right = split_data(data, column_index, value)\n",
    "            overall_entropy = calculate_overall_entropy(data_left, data_right)\n",
    "\n",
    "            # If the overall entropy of this split is lower than the current lowest entropy,\n",
    "            # set the computed entropy as the new lowest and set the new best splitting criteria\n",
    "            if overall_entropy <= lowest_entropy:\n",
    "                lowest_entropy = overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting criteria by Gain Ratio: Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the best feature and value to be the splitting node through gain ratio\n",
    "def determine_best_split_GR(data, potential_splits):\n",
    "    \n",
    "    # Instantiate a variable to store the value of the highest gain ratio\n",
    "    highest_gain_ratio = -1\n",
    "\n",
    "    # Calculate the total entropy of the current data\n",
    "    dataset_entropy = calculate_entropy(data)\n",
    "    \n",
    "    # Loop through the potential splits (both by column and value)\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            # Call helper functions to split the data and then calculate overall entropy\n",
    "            data_left, data_right = split_data(data, column_index, value)\n",
    "            overall_entropy = calculate_overall_entropy(data_left, data_right)\n",
    "            gain_ratio = (dataset_entropy - overall_entropy) / overall_entropy\n",
    "\n",
    "            # If the gain ratio of this split is higher than the current highest gain ratio,\n",
    "            # set the computed gain ratio as the new highest and set the new best splitting criteria\n",
    "            if gain_ratio >= highest_gain_ratio:\n",
    "                highest_gain_ratio = gain_ratio\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting criteria by Gini Index: Helper functions\n",
    "- For each split, the lower the gini index/impurity, the better the split as a lot more of the data can be differentiated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini_index(left_data, right_data):\n",
    "    \n",
    "    # Get the two column values\n",
    "    col_1 = left_data[:,-1]\n",
    "    col_2 = right_data[:,-1]\n",
    "    \n",
    "    # Count each unique values for each column values\n",
    "    _, num_counts_1 = np.unique(col_1, return_counts=True)\n",
    "    _, num_counts_2 = np.unique(col_2, return_counts=True)\n",
    "    \n",
    "    # Calculate the probability of each column values\n",
    "    prob_1 = num_counts_1 / num_counts_1.sum()\n",
    "    prob_2 = num_counts_2 / num_counts_2.sum()\n",
    "    \n",
    "    # Calculate Gini of left and right dataset\n",
    "    gini_left = 1 - sum(prob_1**2)\n",
    "    gini_right = 1 - sum(prob_2**2)\n",
    "    \n",
    "    # Total number of rows in left and right dataset\n",
    "    total_length = len(left_data) + len(right_data)\n",
    "\n",
    "    # Calculate the gini index of the split\n",
    "    gini_index = (len(left_data)/total_length) * gini_left + (len(right_data)/total_length) * gini_right\n",
    "    \n",
    "    return gini_index\n",
    "\n",
    "# Function to determine the best feature and value to be the splitting node through gini index\n",
    "def determine_best_split_GI(data, potential_splits):\n",
    "    \n",
    "    # Instantiate a variable to store the value of the lowest gini index while looping through the potential splits\n",
    "    lowest_GI = 99999\n",
    "    \n",
    "    # Loop through the potential splits (both by column and value)\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            # Call helper functions to split the data and then calculate gini index for that split\n",
    "            data_left, data_right = split_data(data, column_index, value)\n",
    "            current_GI = calculate_gini_index(data_left, data_right)\n",
    "\n",
    "            # If the gini index of this split is lower than the current lowest gini index,\n",
    "            # set the computed gini index as the new lowest and set the new best splitting criteria\n",
    "            if current_GI <= lowest_GI:\n",
    "                lowest_GI = current_GI\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree induction algorithm\n",
    "Important parameters:\n",
    "- A maximum depth parameter prevents the tree from growing too large and causing overfitting (we use a default of 10 to begin with)\n",
    "- Splitting criteria determines the splitting criteria out of the 3(Information gain, Gain Ratio, Gini Index) to be used when building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(df, counter=0, max_depth=10, splitting_criteria=\"gini_index\"):\n",
    "    # Instantiating variables if starting at the root\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    # Check if the data is impure or if the tree has already reached the specified max depth\n",
    "    # If true, returns the classification without splitting\n",
    "    if (check_purity(data)) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        \n",
    "        return classification\n",
    "    \n",
    "    # Splitting algorithm\n",
    "    else:\n",
    "        # Increase counter by one and call helper function to get the potential splits among the features\n",
    "        counter += 1\n",
    "        potential_splits = get_potential_splits(data)\n",
    "\n",
    "        # Use the method of splitting specified\n",
    "        if (splitting_criteria == \"info_gain\"):\n",
    "            split_column, split_value = determine_best_split_IG(data, potential_splits)\n",
    "        elif (splitting_criteria == \"gain_ratio\"):\n",
    "            split_column, split_value = determine_best_split_GR(data, potential_splits)\n",
    "        else:\n",
    "            split_column, split_value = determine_best_split_GI(data, potential_splits)\n",
    "        \n",
    "        data_left, data_right = split_data(data, split_column, split_value)\n",
    "        \n",
    "        # Build the tree\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        question = \"{} = {}\".format(feature_name, split_value)\n",
    "        tree = {question: []}\n",
    "        \n",
    "        # Perform recursion to traverse the new left and right nodes of the tree\n",
    "        yes_answer = build_tree(data_left, counter, max_depth, splitting_criteria)\n",
    "        no_answer = build_tree(data_right, counter, max_depth, splitting_criteria)\n",
    "        \n",
    "        # For cases when data is classified even though it is not pure yet (e.g. tree has reached max depth)\n",
    "        if yes_answer == no_answer:\n",
    "            tree = yes_answer\n",
    "        else:\n",
    "            tree[question].append(yes_answer)\n",
    "            tree[question].append(no_answer)\n",
    "        \n",
    "        return tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classfication function (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(test_data, tree):\n",
    "    # Dictionary that stores all the nodes and it's values]\n",
    "    if isinstance(tree, str):\n",
    "        return tree\n",
    "    else:\n",
    "        question = list(tree.keys())[0]\n",
    "    name_of_feature, operator, val = question.split(\" \")\n",
    "\n",
    "    if str(test_data[name_of_feature]) == val:\n",
    "        ans = tree[question][0]\n",
    "    else:\n",
    "        ans = tree[question][1]\n",
    "\n",
    "    # Check if selected node is a dictionary (base case)\n",
    "    if not isinstance(ans, dict):\n",
    "        return ans\n",
    "    \n",
    "    # If tree is a dictionary, call classify function using test data and remaining tree (recursive part)\n",
    "    else:\n",
    "        remaining_tree = ans\n",
    "        return classify_example(test_data, remaining_tree)\n",
    "\n",
    "# Prediciton function based on decision tree\n",
    "def predict(test_data, tree):\n",
    "    result = []\n",
    "    idx = test_data.index.tolist()\n",
    "    for i in idx:\n",
    "        result.append(classify_example(test_data.loc[i],tree))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of models\n",
    "- Test built decision tree with testing dataset\n",
    "- Compute the mean accuracy of all 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building tree based on Information Gain splitting criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Information Gain tree = 0.9645061728395061\n"
     ]
    }
   ],
   "source": [
    "# Build the tree based on splitting criteria = \"info_gain\"\n",
    "IG_tree = build_tree(train_df, splitting_criteria=\"info_gain\")\n",
    "\n",
    "# Make predictions based off of testing dataset\n",
    "final_prediction_IG = predict(test_df, IG_tree)\n",
    "\n",
    "# Check accuracy of model by comparing actual values with predicted values by calculating the mean of the two values\n",
    "accuracy_IG = (final_prediction_IG == test_df[\"label\"]).mean()\n",
    "\n",
    "# Display accuracy\n",
    "print('Accuracy of Information Gain tree =', accuracy_IG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building tree based on Gain Ratio splitting criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-4cdfe6cab148>:16: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  gain_ratio = (dataset_entropy - overall_entropy) / overall_entropy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gain Ratio tree = 0.9645061728395061\n"
     ]
    }
   ],
   "source": [
    "# Build the tree based on splitting criteria = \"gain_ratio\"\n",
    "GR_tree = build_tree(train_df, splitting_criteria=\"gain_ratio\")\n",
    "\n",
    "# Make predictions based off of testing dataset\n",
    "final_prediction_GR = predict(test_df, GR_tree)\n",
    "\n",
    "# Check accuracy of model by comparing actual values with predicted values and calculating the mean of the two values\n",
    "accuracy_GR = (final_prediction_GR == test_df[\"label\"]).mean()\n",
    "\n",
    "# Display accuracy\n",
    "print('Accuracy of Gain Ratio tree =', accuracy_GR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building tree based on Gini Index splitting criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gini Index tree = 0.9672067901234568\n"
     ]
    }
   ],
   "source": [
    "# Build the tree based on splitting criteria = \"gini_index\"\n",
    "GI_tree = build_tree(train_df, splitting_criteria=\"gini_index\")\n",
    "\n",
    "# Make predictions based off of testing dataset\n",
    "final_prediction_GI = predict(test_df, GI_tree)\n",
    "\n",
    "# Check accuracy of model by comparing actual values with predicted values and calculating the mean of the two values\n",
    "accuracy_GI = (final_prediction_GI == test_df[\"label\"]).mean()\n",
    "\n",
    "# Display accuracy\n",
    "print('Accuracy of Gini Index tree =', accuracy_GI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-pruning helper functions\n",
    "- For each devision node in the tree, determine if we should keep the node or replace it with a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, question):\n",
    "    feature_name, operator, val = question.split()\n",
    "    \n",
    "    df_yes = df[df[feature_name].astype(str) == val]\n",
    "    df_no  = df[df[feature_name].astype(str) != val]\n",
    "    \n",
    "    return df_yes, df_no\n",
    "\n",
    "def determine_leaf(df_train):\n",
    "    return df_train.label.value_counts().index[0]\n",
    "\n",
    "def determine_errors(df_val, tree):\n",
    "    final_predictions = predict(df_val, tree)\n",
    "    actual_val = df_val.label\n",
    "    \n",
    "    return sum(final_predictions != actual_val)\n",
    "\n",
    "def pruning_result(tree, dataframe_train, dataframe_val):\n",
    "    \n",
    "    leaf_node = determine_leaf(dataframe_train)\n",
    "    leaf_errors = determine_errors(dataframe_val, leaf_node)\n",
    "    errors_decision_node = determine_errors(dataframe_val, tree)\n",
    "\n",
    "    if leaf_errors <= errors_decision_node:\n",
    "        return leaf_node\n",
    "    else:\n",
    "        return tree\n",
    "\n",
    "def post_pruning(tree, df_train, df_val):\n",
    "    \n",
    "    question = list(tree.keys())[0]\n",
    "    yes_answer, no_answer = tree[question]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(yes_answer, dict) and not isinstance(no_answer, dict):\n",
    "        return pruning_result(tree, df_train, df_val)\n",
    "        \n",
    "    # recursion to prune the tree\n",
    "    else:\n",
    "        df_train_yes, df_train_no = filter_df(df_train, question)\n",
    "        df_val_yes, df_val_no = filter_df(df_val, question)\n",
    "        \n",
    "        if isinstance(yes_answer, dict):\n",
    "            yes_answer = post_pruning(yes_answer, df_train_yes, df_val_yes)\n",
    "            \n",
    "        if isinstance(no_answer, dict):\n",
    "            no_answer = post_pruning(no_answer, df_train_no, df_val_no)\n",
    "        \n",
    "        tree = {question: [yes_answer, no_answer]}\n",
    "    \n",
    "        return pruning_result(tree, df_train, df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing post-pruning when building the trees and determining the best max_depth parameter to prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-pruning Information Gain decision tree\n",
    "- The metrics show that a maximum depth of 14 seem to be the most optimal for building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_tree</th>\n",
       "      <th>acc_tree_pruned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.869985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.892361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.912423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.940201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.946373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.962577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.974151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.979552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.985725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           acc_tree  acc_tree_pruned\n",
       "max_depth                           \n",
       "5          0.964506         0.869985\n",
       "6          0.964506         0.892361\n",
       "7          0.964506         0.912423\n",
       "8          0.964506         0.940201\n",
       "9          0.964506         0.946373\n",
       "10         0.964506         0.962577\n",
       "11         0.964506         0.974151\n",
       "12         0.964506         0.979552\n",
       "13         0.964506         0.985725\n",
       "14         0.964506         0.986497\n",
       "15         0.964506         0.986497\n",
       "16         0.964506         0.986497\n",
       "17         0.964506         0.986497\n",
       "18         0.964506         0.986497\n",
       "19         0.964506         0.986497\n",
       "20         0.964506         0.986497\n",
       "21         0.964506         0.986497\n",
       "22         0.964506         0.986497\n",
       "23         0.964506         0.986497\n",
       "24         0.964506         0.986497\n",
       "25         0.964506         0.986497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = {\"max_depth\": [], \"acc_tree\": [], \"acc_tree_pruned\": []}\n",
    "\n",
    "# Testing range of max_depth parameter from 5 to 25\n",
    "for n in range (5, 26):\n",
    "    IG_tree = build_tree(train_df, max_depth=n, splitting_criteria=\"info_gain\")\n",
    "    IG_tree_pruned = post_pruning(IG_tree, train_df, prune_df)\n",
    "\n",
    "    metrics[\"max_depth\"].append(n)\n",
    "\n",
    "    final_predictions_IG = predict(test_df, IG_tree)\n",
    "    metrics[\"acc_tree\"].append((final_prediction_IG == test_df[\"label\"]).mean())\n",
    "\n",
    "    final_prediction_IG_pruned = predict(test_df, IG_tree_pruned)\n",
    "    metrics[\"acc_tree_pruned\"].append((final_prediction_IG_pruned == test_df[\"label\"]).mean())\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics = df_metrics.set_index(\"max_depth\")\n",
    "display(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-pruning Gain Ratio decision tree\n",
    "- - The metrics show that a maximum depth of 14 seem to be the most optimal for building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-4cdfe6cab148>:16: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  gain_ratio = (dataset_entropy - overall_entropy) / overall_entropy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_tree</th>\n",
       "      <th>acc_tree_pruned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.869985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.892361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.912423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.940201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.946373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.962577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.974151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.979552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.985725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.964506</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           acc_tree  acc_tree_pruned\n",
       "max_depth                           \n",
       "5          0.964506         0.869985\n",
       "6          0.964506         0.892361\n",
       "7          0.964506         0.912423\n",
       "8          0.964506         0.940201\n",
       "9          0.964506         0.946373\n",
       "10         0.964506         0.962577\n",
       "11         0.964506         0.974151\n",
       "12         0.964506         0.979552\n",
       "13         0.964506         0.985725\n",
       "14         0.964506         0.986497\n",
       "15         0.964506         0.986497\n",
       "16         0.964506         0.986497\n",
       "17         0.964506         0.986497\n",
       "18         0.964506         0.986497\n",
       "19         0.964506         0.986497\n",
       "20         0.964506         0.986497\n",
       "21         0.964506         0.986497\n",
       "22         0.964506         0.986497\n",
       "23         0.964506         0.986497\n",
       "24         0.964506         0.986497\n",
       "25         0.964506         0.986497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = {\"max_depth\": [], \"acc_tree\": [], \"acc_tree_pruned\": []}\n",
    "\n",
    "# Testing range of max_depth parameter from 5 to 25\n",
    "for n in range (5, 26):\n",
    "    GR_tree = build_tree(train_df, max_depth=n, splitting_criteria=\"gain_ratio\")\n",
    "    GR_tree_pruned = post_pruning(GR_tree, train_df, prune_df)\n",
    "\n",
    "    metrics[\"max_depth\"].append(n)\n",
    "\n",
    "    final_predictions_GR = predict(test_df, GR_tree)\n",
    "    metrics[\"acc_tree\"].append((final_prediction_GR == test_df[\"label\"]).mean())\n",
    "\n",
    "    final_prediction_GR_pruned = predict(test_df, GR_tree_pruned)\n",
    "    metrics[\"acc_tree_pruned\"].append((final_prediction_GR_pruned == test_df[\"label\"]).mean())\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics = df_metrics.set_index(\"max_depth\")\n",
    "display(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-pruning Gini Index decision tree\n",
    "- - The metrics show that a maximum depth of 13 seem to be the most optimal for building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_tree</th>\n",
       "      <th>acc_tree_pruned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.875772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.896991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.915509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.940972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.950617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.964506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.975694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.980710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           acc_tree  acc_tree_pruned\n",
       "max_depth                           \n",
       "5          0.967207         0.875772\n",
       "6          0.967207         0.896991\n",
       "7          0.967207         0.915509\n",
       "8          0.967207         0.940972\n",
       "9          0.967207         0.950617\n",
       "10         0.967207         0.964506\n",
       "11         0.967207         0.975694\n",
       "12         0.967207         0.980710\n",
       "13         0.967207         0.986497\n",
       "14         0.967207         0.986497\n",
       "15         0.967207         0.986497\n",
       "16         0.967207         0.986497\n",
       "17         0.967207         0.986497\n",
       "18         0.967207         0.986497\n",
       "19         0.967207         0.986497\n",
       "20         0.967207         0.986497\n",
       "21         0.967207         0.986497\n",
       "22         0.967207         0.986497\n",
       "23         0.967207         0.986497\n",
       "24         0.967207         0.986497\n",
       "25         0.967207         0.986497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = {\"max_depth\": [], \"acc_tree\": [], \"acc_tree_pruned\": []}\n",
    "\n",
    "# Testing range of max_depth parameter from 5 to 25\n",
    "for n in range (5, 26):\n",
    "    GI_tree = build_tree(train_df, max_depth=n, splitting_criteria=\"gini_index\")\n",
    "    GI_tree_pruned = post_pruning(GI_tree, train_df, prune_df)\n",
    "\n",
    "    metrics[\"max_depth\"].append(n)\n",
    "\n",
    "    final_predictions_GI = predict(test_df, GI_tree)\n",
    "    metrics[\"acc_tree\"].append((final_prediction_GI == test_df[\"label\"]).mean())\n",
    "\n",
    "    final_prediction_GI_pruned = predict(test_df, GI_tree_pruned)\n",
    "    metrics[\"acc_tree_pruned\"].append((final_prediction_GI_pruned == test_df[\"label\"]).mean())\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics = df_metrics.set_index(\"max_depth\")\n",
    "display(df_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86d27ba32ed56a20e842ab0c9e0ab1fb322f2a683dcb2ce650fbde54e73080ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
